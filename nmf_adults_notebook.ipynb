{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import rand_score\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "\n",
    "\n",
    "def load_data(hemisphere):\n",
    "    X = pd.read_csv('https://raw.githubusercontent.com/JonahKember/hippocampus_clustering/main/' + hemisphere + '_nmf_input_raw.csv')\n",
    "    X = X.to_numpy()\n",
    "    return(X)\n",
    "\n",
    "\n",
    "def get_age(hemisphere):\n",
    "    Y = pd.read_csv(hemisphere + '_age.csv')\n",
    "    age = Y['Age'].to_numpy()\n",
    "    return(age)\n",
    "\n",
    "\n",
    "def run_nmf(X,k):\n",
    "    \n",
    "    '''1. Rescale columns of X to the interval [0,1].\n",
    "    2. Run Non-Negative matrix factorization on X with k components.'''\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    model = NMF(n_components = k, init = 'random', max_iter = 10000)\n",
    "    model.fit_transform(X)\n",
    "    \n",
    "    W = model.transform(X)\n",
    "    clusters = np.argmax(W,1)\n",
    "\n",
    "    return(clusters, model)\n",
    "\n",
    "def get_nmf_similarity(X, k, n_shuffle = 5):\n",
    "    \n",
    "    '''Calculate the stability of NMF components. \n",
    "    1. Randomly split the matrix X in half n_shuffle times.\n",
    "    2. Run NMF on each half (with k components).\n",
    "    3. Calculate the adjusted Rand index between the clusters output from each half.'''\n",
    "\n",
    "    rand_indices = np.zeros(n_shuffle)\n",
    "\n",
    "    for split in range(n_shuffle):\n",
    "\n",
    "        # Generate randomly shuffled indices (seed set for reproducibility).\n",
    "        np.random.seed(split)\n",
    "        idx = np.array_split (np.random.permutation(X.shape[1]),2)\n",
    "\n",
    "        # Get NMF clusters for each split.\n",
    "        clust_1 = run_nmf(X[:,idx[0]],k)[0]\n",
    "        clust_2 = run_nmf(X[:,idx[1]],k)[0]\n",
    "\n",
    "        # Calculate the adjusted Rand index.\n",
    "        rand_indices[split] = adjusted_rand_score(clust_1,clust_2)\n",
    "        \n",
    "    print('Similarity for k = '+ str(k) + ' is ' + str(np.mean(rand_indices)))\n",
    "    \n",
    "    return(rand_indices)\n",
    "\n",
    "def get_nmf_error(X, k_vals = np.arange(1,10)):\n",
    "    \n",
    "    '''Calculate the reconstruction error of NMF components.''' \n",
    "\n",
    "    error = np.zeros(len(k_vals) + 1)\n",
    "\n",
    "    for k in k_vals:\n",
    "\n",
    "        # Get NMF clusters for each split.\n",
    "        model = run_nmf(X,k)[1]\n",
    "        error[k] = model.reconstruction_err_\n",
    "        \n",
    "        print('Reconstruction error for k = '+ str(k) + ' is ' + str(np.mean(error[k])))\n",
    "    \n",
    "    return(error)\n",
    "\n",
    "\n",
    "def clusters_to_nii(k, hemisphere,clusters):\n",
    "\n",
    "    if hemisphere == 'right':\n",
    "        hem_label = 1\n",
    "    elif hemisphere == 'left':\n",
    "        hem_label = 2\n",
    "\n",
    "    # Open majority-vote label.\n",
    "    majority_vote = nib.load('majority_vote_label.nii')\n",
    "\n",
    "    # Get nifti file information.\n",
    "    labels = majority_vote.get_fdata()\n",
    "\n",
    "    # Initialize empty matrix, fill with cluster labels, write to nifti.\n",
    "    nii = np.zeros(labels.shape, dtype = np.float64)\n",
    "    nii[labels == hem_label] = clusters\n",
    "    nii = Nifti1Image(nii, affine = majority_vote.affine, header = majority_vote.header)\n",
    "\n",
    "    nib.save(nii, str(hemisphere + '_nmf_clusters_k' + str(k) + '.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_adults(hemisphere,age_threshold):\n",
    "\n",
    "    X = load_data(hemisphere)\n",
    "    age = get_age(hemisphere)\n",
    "\n",
    "    idx = (age > age_threshold)\n",
    "\n",
    "    X = X[:,np.concatenate((idx,idx,idx))]\n",
    "    return(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for k = 1 is 1.0\n",
      "Similarity for k = 2 is 0.4029005640572717\n",
      "Similarity for k = 3 is 0.4828470446924924\n",
      "Similarity for k = 4 is 0.35566823736872377\n",
      "Similarity for k = 5 is 0.37828510502615403\n",
      "Similarity for k = 6 is 0.37044734933034174\n",
      "Similarity for k = 7 is 0.39529619692759427\n",
      "Similarity for k = 8 is 0.2713622014117951\n",
      "Similarity for k = 9 is 0.3328772042587498\n",
      "Similarity for k = 10 is 0.29675547120251433\n",
      "Similarity for k = 11 is 0.1930869212142759\n",
      "Similarity for k = 12 is 0.1934104723621019\n",
      "Similarity for k = 13 is 0.1920966081758651\n",
      "Similarity for k = 14 is 0.2742498777732353\n"
     ]
    }
   ],
   "source": [
    "# Number of data-set splits.\n",
    "n_shuffle = 5\n",
    "\n",
    "# Number of k-values to explore.\n",
    "n_k = 15\n",
    "\n",
    "X = load_data_adults('right',16)\n",
    "\n",
    "# Track similarity of NMF components across range of k-values.\n",
    "k_similarity = np.zeros([n_k,n_shuffle])\n",
    "for k in range(1,n_k):\n",
    "    k_similarity[k,:] = get_nmf_similarity(X, k, n_shuffle = n_shuffle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of k-values to explore.\n",
    "k_vals = np.arange(1,15)\n",
    "X = load_data('right')\n",
    "\n",
    "error = get_nmf_error(X, k_vals = k_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the similarity.\n",
    "x = np.arange(k_similarity.shape[0])\n",
    "y = np.mean(k_similarity,1)\n",
    "yerr = np.std(k_similarity, axis = 1)/np.sqrt(k_similarity.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].errorbar(x[1:],y[1:], yerr = yerr[1:])\n",
    "\n",
    "ax[0].set_xlim([0,15])\n",
    "ax[0].set_xlabel('k')\n",
    "ax[0].set_ylabel('Adjusted Rand Index')\n",
    "\n",
    "# Plot the reconstruction error.\n",
    "x = np.arange(error.shape[0])\n",
    "ax[1].plot(x[1:],error[1:])\n",
    "\n",
    "ax[1].set_xlim([0,15])\n",
    "ax[1].set_xlabel('k')\n",
    "ax[1].set_ylabel('Reconstruction error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subfield labels.\n",
    "y = pd.read_csv('right_subfield_labels.csv')\n",
    "y = y.to_numpy()\n",
    "y = y.reshape(y.shape[0],)\n",
    "\n",
    "clusters = run_nmf(X,5)[0]\n",
    "\n",
    "model = LinearDiscriminantAnalysis(n_components = 2)\n",
    "model.fit_transform(X,clusters)\n",
    "lda_components = model.transform(X)\n",
    "\n",
    "# Plot Subfields against NMF components in LDA space. \n",
    "fig, ax = plt.subplots(1,2,figsize = [15,5])\n",
    "\n",
    "for k in range(np.max(clusters) + 1):\n",
    "    ax[0].plot(lda_components[y == k,0], lda_components[y == k,1], marker='o', linestyle='')    \n",
    "    ax[1].plot(lda_components[clusters == k,0], lda_components[clusters == k,1], marker='o', linestyle='') \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote = nib.load('majority_vote_label.nii')\n",
    "hcpd = nib.load('right_components_k5.nii')\n",
    "hcp = nib.load('raihann_warped.nii.gz')\n",
    "\n",
    "\n",
    "labels = majority_vote.get_fdata()\n",
    "\n",
    "hcpd = hcpd.get_fdata()\n",
    "hcpd = hcpd[labels == 1]\n",
    "\n",
    "hcp = hcp.get_fdata()\n",
    "hcp = hcp[labels == 1]\n",
    "hcp = np.round(hcp)\n",
    "\n",
    "hcpd = hcpd.astype(int)\n",
    "hcp = hcp.astype(int)\n",
    "\n",
    "print(hcpd)\n",
    "print(hcp)\n",
    "adjusted_rand_score(hcpd,hcp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
